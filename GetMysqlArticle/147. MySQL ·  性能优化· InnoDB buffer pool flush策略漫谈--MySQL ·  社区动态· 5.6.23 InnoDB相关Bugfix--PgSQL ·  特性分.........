<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html lang="zh-cn" dir="ltr">
<head>
<title>MySQL内核月报 2015.02 - 淘宝数据库研发组</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta name="generator" content="MediaWiki 1.16.5" />
<link rel="shortcut icon" href="/favicon.ico" />
<link rel="search" type="application/opensearchdescription+xml" href="/opensearch_desc.php" title="淘宝数据库研发组 (zh-cn)" />
<link title="Creative Commons" type="application/rdf+xml" href="/index.php?title=MySQL%E5%86%85%E6%A0%B8%E6%9C%88%E6%8A%A5_2015.02&amp;action=creativecommons" rel="meta" />
<link rel="copyright" href="http://www.gnu.org/copyleft/fdl.html" />
<link rel="alternate" type="application/atom+xml" title="淘宝数据库研发组的Atom订阅" href="/index.php?title=%E7%89%B9%E6%AE%8A:%E6%9C%80%E8%BF%91%E6%9B%B4%E6%94%B9&amp;feed=atom" />
<link rel="stylesheet" href="/skins/common/shared.css?270" media="screen" />
<link rel="stylesheet" href="/skins/common/commonPrint.css?270" media="print" />
<link rel="stylesheet" href="/skins/monobook/main.css?270" media="screen" />
<!--[if lt IE 5.5000]><link rel="stylesheet" href="/skins/monobook/IE50Fixes.css?270" media="screen" /><![endif]-->
<!--[if IE 5.5000]><link rel="stylesheet" href="/skins/monobook/IE55Fixes.css?270" media="screen" /><![endif]-->
<!--[if IE 6]><link rel="stylesheet" href="/skins/monobook/IE60Fixes.css?270" media="screen" /><![endif]-->
<!--[if IE 7]><link rel="stylesheet" href="/skins/monobook/IE70Fixes.css?270" media="screen" /><![endif]-->
<link rel="stylesheet" href="/index.php?title=MediaWiki:Common.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=18000&amp;action=raw&amp;maxage=18000" />
<link rel="stylesheet" href="/index.php?title=MediaWiki:Print.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=18000&amp;action=raw&amp;maxage=18000" media="print" />
<link rel="stylesheet" href="/index.php?title=MediaWiki:Monobook.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=18000&amp;action=raw&amp;maxage=18000" />
<link rel="stylesheet" href="/index.php?title=-&amp;action=raw&amp;maxage=18000&amp;gen=css" />
<script>
var skin="monobook",
stylepath="/skins",
wgUrlProtocols="http\\:\\/\\/|https\\:\\/\\/|ftp\\:\\/\\/|irc\\:\\/\\/|gopher\\:\\/\\/|telnet\\:\\/\\/|nntp\\:\\/\\/|worldwind\\:\\/\\/|mailto\\:|news\\:|svn\\:\\/\\/",
wgArticlePath="/index.php?title=$1",
wgScriptPath="",
wgScriptExtension=".php",
wgScript="/index.php",
wgVariantArticlePath=false,
wgActionPaths={},
wgServer="http://mysql.taobao.org",
wgCanonicalNamespace="",
wgCanonicalSpecialPageName=false,
wgNamespaceNumber=0,
wgPageName="MySQL内核月报_2015.02",
wgTitle="MySQL内核月报 2015.02",
wgAction="view",
wgArticleId=135,
wgIsArticle=true,
wgUserName=null,
wgUserGroups=null,
wgUserLanguage="zh-cn",
wgContentLanguage="zh-cn",
wgBreakFrames=false,
wgCurRevisionId=1226,
wgVersion="1.16.5",
wgEnableAPI=true,
wgEnableWriteAPI=true,
wgSeparatorTransformTable=["", ""],
wgDigitTransformTable=["", ""],
wgMainPageTitle="首页",
wgFormattedNamespaces={"-2": "媒体", "-1": "特殊", "0": "", "1": "讨论", "2": "用户", "3": "用户讨论", "4": "淘宝数据库研发组", "5": "淘宝数据库研发组讨论", "6": "文件", "7": "文件讨论", "8": "MediaWiki", "9": "MediaWiki讨论", "10": "模板", "11": "模板讨论", "12": "帮助", "13": "帮助讨论", "14": "分类", "15": "分类讨论"},
wgNamespaceIds={"媒体": -2, "特殊": -1, "": 0, "讨论": 1, "用户": 2, "用户讨论": 3, "淘宝数据库研发组": 4, "淘宝数据库研发组讨论": 5, "文件": 6, "文件讨论": 7, "mediawiki": 8, "mediawiki讨论": 9, "模板": 10, "模板讨论": 11, "帮助": 12, "帮助讨论": 13, "分类": 14, "分类讨论": 15, "对话": 1, "用户对话": 3, "图像": 6, "档案": 6, "image": 6, "image_talk": 7, "图像对话": 7, "图像讨论": 7, "档案对话": 7, "档案讨论": 7, "文件对话": 7, "模板对话": 11, "帮助对话": 13, "分类对话": 15},
wgSiteName="淘宝数据库研发组",
wgCategories=[],
wgRestrictionEdit=[],
wgRestrictionMove=[];
</script><script src="/skins/common/wikibits.js?270"></script>
<script src="/skins/common/ajax.js?270"></script>
<script src="/index.php?title=-&amp;action=raw&amp;gen=js&amp;useskin=monobook&amp;270"></script>

</head>
<body class="mediawiki ltr ns-0 ns-subject page-MySQL内核月报_2015_02 skin-monobook">
<div id="globalWrapper">
<div id="column-content"><div id="content" >
	<a id="top"></a>
	
	<h1 id="firstHeading" class="firstHeading">MySQL内核月报 2015.02</h1>
	<div id="bodyContent">
		<h3 id="siteSub">出自淘宝数据库研发组</h3>
		<div id="contentSub"></div>
		<div id="jump-to-nav">跳转到： <a href="#column-one">导航</a>, <a href="#searchInput">搜索</a></div>
		<!-- start content -->
<table id="toc" class="toc"><tr><td><div id="toctitle"><h2>目录</h2></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#MySQL_.C2.B7_.E6.80.A7.E8.83.BD.E4.BC.98.E5.8C.96.C2.B7_InnoDB_buffer_pool_flush.E7.AD.96.E7.95.A5.E6.BC.AB.E8.B0.88"><span class="tocnumber">1</span> <span class="toctext">MySQL ·  性能优化· InnoDB buffer pool flush策略漫谈</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#MySQL_.C2.B7_.E7.A4.BE.E5.8C.BA.E5.8A.A8.E6.80.81.C2.B7_5.6.23_InnoDB.E7.9B.B8.E5.85.B3Bugfix"><span class="tocnumber">2</span> <span class="toctext">MySQL ·  社区动态· 5.6.23 InnoDB相关Bugfix</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="#PgSQL_.C2.B7_.E7.89.B9.E6.80.A7.E5.88.86.E6.9E.90.C2.B7_Replication_Slot"><span class="tocnumber">3</span> <span class="toctext">PgSQL ·  特性分析· Replication Slot</span></a></li>
<li class="toclevel-1 tocsection-4"><a href="#PgSQL_.C2.B7_.E7.89.B9.E6.80.A7.E5.88.86.E6.9E.90.C2.B7_pg_prewarm"><span class="tocnumber">4</span> <span class="toctext">PgSQL ·  特性分析· pg_prewarm</span></a></li>
<li class="toclevel-1 tocsection-5"><a href="#MySQL_.C2.B7_.E7.AD.94.E7.96.91.E9.87.8A.E6.83.91.C2.B7_InnoDB.E4.B8.A2.E5.A4.B1.E8.87.AA.E5.A2.9E.E5.80.BC"><span class="tocnumber">5</span> <span class="toctext">MySQL · 答疑释惑· InnoDB丢失自增值</span></a></li>
<li class="toclevel-1 tocsection-6"><a href="#MySQL_.C2.B7_.E7.AD.94.E7.96.91.E9.87.8A.E6.83.91.C2.B7_5.5_.E5.92.8C_5.6_.E6.97.B6.E9.97.B4.E7.B1.BB.E5.9E.8B.E5.85.BC.E5.AE.B9.E9.97.AE.E9.A2.98"><span class="tocnumber">6</span> <span class="toctext">MySQL · 答疑释惑· 5.5 和 5.6 时间类型兼容问题</span></a></li>
<li class="toclevel-1 tocsection-7"><a href="#MySQL_.C2.B7_.E6.8D.89.E8.99.AB.E5.8A.A8.E6.80.81.C2.B7_.E5.8F.98.E9.87.8F.E4.BF.AE.E6.94.B9.E5.AF.BC.E8.87.B4binlog.E9.94.99.E8.AF.AF"><span class="tocnumber">7</span> <span class="toctext">MySQL · 捉虫动态·  变量修改导致binlog错误</span></a></li>
<li class="toclevel-1 tocsection-8"><a href="#MariaDB_.C2.B7_.E7.89.B9.E6.80.A7.E5.88.86.E6.9E.90.C2.B7_.E8.A1.A8.2F.E8.A1.A8.E7.A9.BA.E9.97.B4.E5.8A.A0.E5.AF.86"><span class="tocnumber">8</span> <span class="toctext">MariaDB ·  特性分析· 表/表空间加密</span></a></li>
<li class="toclevel-1 tocsection-9"><a href="#MariaDB_.C2.B7_.E7.89.B9.E6.80.A7.E5.88.86.E6.9E.90.C2.B7_Per-query_variables"><span class="tocnumber">9</span> <span class="toctext">MariaDB ·  特性分析· Per-query variables</span></a></li>
<li class="toclevel-1 tocsection-10"><a href="#TokuDB_.C2.B7_.E7.89.B9.E6.80.A7.E5.88.86.E6.9E.90.C2.B7_.E6.97.A5.E5.BF.97.E8.AF.A6.E8.A7.A3"><span class="tocnumber">10</span> <span class="toctext">TokuDB ·  特性分析· 日志详解</span></a></li>
</ul>
</td></tr></table><script>if (window.showTocToggle) { var tocShowText = "显示"; var tocHideText = "隐藏"; showTocToggle(); } </script>
<h2> <span class="mw-headline" id="MySQL_.C2.B7_.E6.80.A7.E8.83.BD.E4.BC.98.E5.8C.96.C2.B7_InnoDB_buffer_pool_flush.E7.AD.96.E7.95.A5.E6.BC.AB.E8.B0.88"> MySQL ·  性能优化· InnoDB buffer pool flush策略漫谈 </span></h2>
<p><b>背景</b>
</p><p>我们知道InnoDB使用buffer pool来缓存从磁盘读取到内存的数据页。buffer pool通常由数个内存块加上一组控制结构体对象组成。内存块的个数取决于buffer pool instance的个数，不过在5.7版本中开始默认以128M（可配置）的chunk单位分配内存块，这样做的目的是为了支持buffer pool的在线动态调整大小。
</p><p>Buffer pool的每个内存块通过mmap的方式分配内存，因此你会发现，在实例启动时虚存很高，而物理内存很低。这些大片的内存块又按照16KB划分为多个frame，用于存储数据页。
</p><p>虽然大多数情况下buffer pool是以16KB来存储数据页，但有一种例外：使用压缩表时，需要在内存中同时存储压缩页和解压页，对于压缩页，使用Binary buddy allocator算法来分配内存空间。例如我们读入一个8KB的压缩页，就从buffer pool中取一个16KB的block，取其中8KB，剩下的8KB放到空闲链表上；如果紧跟着另外一个4KB的压缩页读入内存，就可以从这8KB中分裂4KB，同时将剩下的4KB放到空闲链表上。
</p><p>为了管理buffer pool，每个buffer pool instance 使用如下几个链表来管理：
</p>
<ul><li>LRU链表包含所有读入内存的数据页；
</li><li>Flush_list包含被修改过的脏页；
</li><li>unzip_LRU包含所有解压页；
</li><li>Free list上存放当前空闲的block。
</li></ul>
<p><br />
另外为了避免查询数据页时扫描LRU，还为每个buffer pool instance维护了一个page hash，通过space id 和page no可以直接找到对应的page。
</p><p>一般情况下，当我们需要读入一个Page时，首先根据space id 和page no找到对应的buffer pool instance。然后查询page hash，如果page hash中没有，则表示需要从磁盘读取。在读盘前首先我们需要为即将读入内存的数据页分配一个空闲的block。当free list上存在空闲的block时，可以直接从free list上摘取；如果没有，就需要从unzip_lru 或者 lru上驱逐page。
</p><p>这里需要遵循一定的原则（参考函数buf_LRU_scan_and_free_block , 5.7.5）：
</p>
<ol><li>首先尝试从unzip_lru上驱逐解压页；
</li><li>如果没有，再尝试从Lru链表上驱逐Page；
</li><li>如果还是无法从Lru上获取到空闲block，用户线程就会参与刷脏，尝试做一次SINGLE PAGE FLUSH，单独从Lru上刷掉一个脏页，然后再重试。
</li></ol>
<p>Buffer pool中的page被修改后，不是立刻写入磁盘，而是由后台线程定时写入，和大多数数据库系统一样，脏页的写盘遵循日志先行WAL原则，因此在每个block上都记录了一个最近被修改时的Lsn，写数据页时需要确保当前写入日志文件的redo不低于这个Lsn。
</p><p>然而基于WAL原则的刷脏策略可能带来一个问题：当数据库的写入负载过高时，产生redo log的速度极快，redo log可能很快到达同步checkpoint点。这时候需要进行刷脏来推进Lsn。由于这种行为是由用户线程在检查到redo log空间不够时触发，大量用户线程将可能陷入到这段低效的逻辑中，产生一个明显的性能拐点。
</p><p><br />
<b>Page Cleaner线程</b>
</p><p>在MySQL5.6中，开启了一个独立的page cleaner线程来进行刷lru list 和flush list。默认每隔一秒运行一次，5.6版本里提供了一大堆的参数来控制page cleaner的flush行为，包括：
</p>
<pre>innodb_adaptive_flushing_lwm， 
innodb_max_dirty_pages_pct_lwm
innodb_flushing_avg_loops
innodb_io_capacity_max
innodb_lru_scan_depth
</pre>
<p>这里我们不一一介绍，总的来说，如果你发现redo log推进的非常快，为了避免用户线程陷入刷脏，可以通过调大innodb_io_capacity_max来解决，该参数限制了每秒刷新的脏页上限，调大该值可以增加Page cleaner线程每秒的工作量。如果你发现你的系统中free list不足，总是需要驱逐脏页来获取空闲的block时，可以适当调大innodb_lru_scan_depth
。该参数表示从每个buffer pool instance的lru上扫描的深度，调大该值有助于多释放些空闲页，避免用户线程去做single page flush。
</p><p>为了提升扩展性和刷脏效率，在5.7.4版本里引入了多个page cleaner线程，从而达到并行刷脏的效果。目前Page cleaner并未和buffer pool绑定，其模型为一个协调线程 + 多个工作线程，协调线程本身也是工作线程。因此如果innodb_page_cleaners设置为4，那么就是一个协调线程，加3个工作线程，工作方式为生产者-消费者。工作队列长度为buffer pool instance的个数，使用一个全局slot数组表示。
</p><p>协调线程在决定了需要flush的page数和lsn_limit后，会设置slot数组，将其中每个slot的状态设置为PAGE_CLEANER_STATE_REQUESTED, 并设置目标page数及lsn_limit，然后唤醒工作线程 (pc_request)
</p><p>工作线程被唤醒后，从slot数组中取一个未被占用的slot，修改其状态，表示已被调度，然后对该slot所对应的buffer pool instance进行操作。直到所有的slot都被消费完后，才进入下一轮。通过这种方式，多个page cleaner线程实现了并发flush buffer pool，从而提升flush dirty page/lru的效率。
</p><p><br />
<b>MySQL5.7的InnoDB flush策略优化</b>
</p><p>在之前版本中，因为可能同时有多个线程操作buffer pool刷page （在刷脏时会释放buffer pool mutex），每次刷完一个page后需要回溯到链表尾部，使得扫描bp链表的时间复杂度最差为O（N*N）。 
</p><p>在5.6版本中针对Flush list的扫描做了一定的修复，使用一个指针来记录当前正在flush的page，待flush操作完成后，再看一下这个指针有没有被别的线程修改掉，如果被修改了，就回溯到链表尾部，否则无需回溯。但这个修复并不完整，在最差的情况下，时间复杂度依旧不理想。
</p><p>因此在5.7版本中对这个问题进行了彻底的修复，使用多个名为hazard pointer的指针，在需要扫描LIST时，存储下一个即将扫描的目标page，根据不同的目的分为几类：
</p>
<ul><li> flush_hp: 用作批量刷FLUSH LIST 
</li><li> lru_hp: 用作批量刷LRU LIST 
</li><li> lru_scan_itr: 用于从LRU链表上驱逐一个可替换的page，总是从上一次扫描结束的位置开始，而不是LRU尾部 
</li><li> single_scan_itr: 当buffer pool中没有空闲block时，用户线程会从FLUSH LIST上单独驱逐一个可替换的page 或者 flush一个脏页，总是从上一次扫描结束的位置开始，而不是LRU尾部。
</li></ul>
<p>后两类的hp都是由用户线程在尝试获取空闲block时调用，只有在推进到某个buf_page_t::old被设置成true的page (大约从Lru链表尾部起至总长度的八分之三位置的page)时， 再将指针重置到Lru尾部。
</p><p>这些指针在初始化buffer pool时分配，每个buffer pool instance都拥有自己的hp指针。当某个线程对buffer pool中的page进行操作时，例如需要从LRU中移除Page时，如果当前的page被设置为hp，就要将hp更新为当前Page的前一个page。当完成当前page的flush操作后，直接使用hp中存储的page指针进行下一轮flush。
</p><p><br />
<b>社区优化</b>
</p><p>一如既往的，Percona Server在5.6版本中针对buffer pool flush做了不少的优化，主要的修改包括如下几点：
</p>
<ul><li>优化刷LRU流程buf_flush_LRU_tail<br />该函数由page cleaner线程调用。
<ul><li>原生的逻辑：依次flush 每个buffer pool instance，每次扫描的深度通过参数innodb_lru_scan_depth来配置。而在每个instance内，又分成多个chunk来调用；
</li><li>修改后的逻辑为：每次flush一个buffer pool的LRU时，只刷一个chunk，然后再下一个instance，刷完所有instnace后，再回到前面再刷一个chunk。简而言之，把集中的flush操作进行了分散，其目的是分散压力，避免对某个instance的集中操作，给予其他线程更多访问buffer pool的机会。
</li></ul>
</li></ul>
<ul><li>允许设定刷LRU/FLUSH LIST的超时时间，防止flush操作时间过长导致别的线程（例如尝试做single page flush的用户线程）stall住；当到达超时时间时,page cleaner线程退出flush。
</li></ul>
<ul><li>避免用户线程参与刷buffer pool<br /> 当用户线程参与刷buffer pool时，由于线程数的不可控，将产生严重的竞争开销，例如free list不足时做single page flush，以及在redo空间不足时，做dirty page flush，都会严重影响性能。Percona Server允许选择让page cleaner线程来做这些工作，用户线程只需要等待即可。出于效率考虑，用户还可以设置page cleaner线程的cpu调度优先级。<br />另外在Page cleaner线程经过优化后，可以知道系统当前处于同步刷新状态，可以去做更激烈的刷脏(furious  flush)，用户线程参与到其中，可能只会起到反作用。
</li></ul>
<ul><li>允许设置page cleaner线程，purge线程，io线程，master线程的CPU调度优先级，并优先获得InnoDB的mutex。
</li></ul>
<ul><li>使用新的独立后台线程来刷buffer pool的LRU链表，将这部分工作负担从page cleaner线程剥离。<br /> 实际上就是直接转移刷LRU的代码到独立线程了。从之前Percona的版本来看，都是在不断的强化后台线程，让用户线程少参与到刷脏/checkpoint这类耗时操作中。
</li></ul>
<h2> <span class="mw-headline" id="MySQL_.C2.B7_.E7.A4.BE.E5.8C.BA.E5.8A.A8.E6.80.81.C2.B7_5.6.23_InnoDB.E7.9B.B8.E5.85.B3Bugfix"> MySQL ·  社区动态· 5.6.23 InnoDB相关Bugfix </span></h2>
<p>本节摘取了MySQL5.6.23的几个和InnoDB相关的主要bugfix，简单阐述下问题及解决方案。 
</p><p><br />
<b>问题一</b>
</p><p>当执行FLUSH TABLE..FOR EXPORT命令时，会暂停purge线程的操作。这一步通过设置一个标记purge_sys-&gt;state的值为PURGE_STATE_STOP来告诉purge线程该停下来歇歇了。
</p><p>然而如果Purge线程当前正在函数srv_do_purge中工作，该函数会执行一个while循环，退出条件是当前server shutdown，或者上次purge的page数为0，并没有检查purge线程的状态是否被设置为PURGE_STATE_STOP; 很显然，如果当前的history list非常长，那么可能需要等待purge完成后，才能退出循环，而在用户看来，就好像hang了很久一样。推长history list 很容易：开启一个打开read view的事务（例如RR级别下执行一个SELECT）不做提交，同时有并发的DML，跑一段时间history list就上去了。
</p><p><br />
<b>解决</b>
</p><p>在函数srv_do_purge函数的while退出条件中加上purge线程状态判断，如果被设置为PURGE_STATE_STOP，就退出循环。
</p><p><a href="https://github.com/mysql/mysql-server/commit/f9a1df899b724d26d7997a49e6403bbe90024bf3" class="external text" rel="nofollow">补丁</a>
</p><p><br />
<b>问题二</b>
</p><p>在执行InnoDB crash recovery阶段，如果发现不合法的大字段，就会去调用函数ib_warn_row_too_big 去打印一条warning，函数为push_warning_printf。然而这个函数的目的是给客户端返回一条warning，而这时候系统还在崩溃恢复阶段，并没有合法的thd对象，因此造成系统崩溃。
</p><p>Tips：这个bug是在升级到新版本5.6出现的，最根本的原因是5.6新版本对大字段长度做的约束。早期版本5.6及之前的版本，我们可以定义非常大的blob字段，但如果字段太长，对这些字段的修改，可能导致redo log的checkpoint点被覆盖，因为计算redo log 空间是否足够，并没有依赖即将插入的redo 记录长度，而仅仅是保留一定的比例。因此在5.6.22版本中做了限制：如果blob的长度超过innodb_log_file_size * innodb_log_files_in_group的十分之一时，就会更新失败，给用户返回DB_TOO_BIG_RECORD的错误码。这个问题在5.7版本里被彻底解决：每写4个blob外部存储页，检查一次redo log空间是否足够，如果不够用，就推进checkpoint点。
</p><p><b>解决</b>
</p><p>在函数ib_warn_row_too_big中判断当前线程thd是否被初始化，如果为NULL，直接返回，不调用push_warning_printf。
</p><p><a href="https://github.com/mysql/mysql-server/commit/901ce5314b6b0d4115b0237491e2afaafe5a274e" class="external text" rel="nofollow">补丁</a>
</p><p><br />
<b>问题三</b>
</p><p>当我们通过alter语句修改一个被外键约束的列名时，由于没有从数据词典cache中将包含老列名的cache项驱逐掉，导致重载外键约束时失败。
</p><p>举个简单的例子：
</p>
<pre>root@sb1 12:37:13&gt;CREATE TABLE t1 (a INT NOT NULL,  b INT NOT NULL,  INDEX idx(a)) ENGINE=InnoDB;
Query OK, 0 rows affected (0.00 sec)
</pre>
<pre>root@sb1 12:37:26&gt;CREATE TABLE t2 (a INT KEY,  b INT,  INDEX ind(b),  FOREIGN KEY (b) REFERENCES t1(a) ON DELETE CASCADE ON UPDATE CASCADE)  ENGINE=InnoDB;
Query OK, 0 rows affected (0.00 sec)
</pre>
<pre>root@sb1 12:37:41&gt;ALTER TABLE t1 CHANGE a id INT;
Query OK, 0 rows affected, 1 warning (0.01 sec)
Records: 0  Duplicates: 0  Warnings: 1
</pre>
<pre>root@sb1 12:37:48&gt;show warnings;
+-------+------+-----------------------------------+
| Level | Code | Message                           |
+-------+------+-----------------------------------+
| Error | 1215 | Cannot add foreign key constraint |
+-------+------+-----------------------------------+
1 row in set (0.00 sec)
</pre>
<pre>root@sb1 12:47:39&gt;show create table t1\G
*************************** 1. row ***************************
       Table: t1
Create Table: CREATE TABLE `t1` (
  `id` int(11) DEFAULT NULL,
  `b` int(11) NOT NULL,
  KEY `idx` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8
1 row in set (0.00 sec)
</pre>
<pre>root@sb1 12:52:08&gt;INSERT INTO t2 VALUES (56, 6);
ERROR 1452 (23000): Cannot add or update a child row: a foreign key constraint fails (`sb1`.`t2`, CONSTRAINT `t2_ibfk_1` FOREIGN KEY (`b`) REFERENCES `t1` (`a`) ON DELETE CASCADE ON UPDATE CASCADE)
</pre>
<p>可以看到，尽管t1表的a列已经被rename成 id，但打印出来的信息也并没有更正。
</p><p><b>解决</b>
</p><p>当被外键约束的列名被修改时，将对应的外键项从数据词典cache中驱逐，当其被随后重新加载时就会使用新的对象。
</p><p><a href="https://github.com/mysql/mysql-server/commit/a54364d2d1c147d6c325c818057de470672f8e3d" class="external text" rel="nofollow">补丁</a>
</p><p><br />
<b>问题四</b>
</p><p>如上文所提到的，在新版本InnoDB中，对blob字段的数据操作需要保证其不超过总的redo log file大小的十分之一，但是返回的错误码DB_TOO_BIG_RECORD及打印的信息太容易让人误解，大概如下：
</p>
<pre>ERROR 42000: Row size too large (&gt; ####). Changing some columns to TEXT or BLOB or using ROW_FORMAT=DYNAMIC or ROW_FORMAT=COMPRESSED may help. In current row format, BLOB prefix of 768 bytes is stored inline
</pre>
<p><b>解决</b>
</p><p>输出更合适、更直观的错误信息，如下：
</p>
<pre>ERROR 42000: The size of BLOB/TEXT data inserted in one transaction is greater than 10% of redo log size. Increase the redo log size using innodb_log_file_size.
</pre>
<p><a href="https://github.com/mysql/mysql-server/commit/4423b9b5633d91e5793ee637ac068059001f85ba" class="external text" rel="nofollow">补丁</a>
</p><p><br />
<b>问题五</b>
</p><p>FLUSH TABLE操作在某些情况下可能导致实例crash。 例如如下执行序列：
</p>
<pre>mysql&gt; CREATE TABLE t1(C TEXT CHARACTER SET UJIS) ENGINE=INNODB;
Query OK, 0 rows affected (0.00 sec)
 
mysql&gt; LOCK TABLES t1 WRITE,t1 AS t0 READ,t1 AS t2 READ;
Query OK, 0 rows affected (0.00 sec)

mysql&gt; FLUSH TABLE t1;   ---- 实例CRASH
</pre>
<p>当执行FLUSH TABLE时，在重载表cache时，InnoDB层会针对每个表设置其状态（ha_innobase::store_lock）。如果执行FLUSH 操作，并且加的是读锁时，就会调用函数row_quiesce_set_state将table-&gt;quiesce设置为QUIESCE_START。在上例中，表t1的两个表名表均加读锁，造成重复设置状态为QUIESCE_START，导致断言失败。
</p><p>Tips：在5.6版本中，虽然有明确的FLUSH TABLE..FOR EXPORT命令来协助转储ibd文件。但实际上，简单的FLUSH TABLE操作默认就会产生一个tbname.cfg的配置文件，拷贝该文件和ibd，可以将数据转移到其他实例上。table-&gt;quiesce用于标识操作状态，例如，如果标识为QUIESCE_START，就会在函数ha_innobase::external_lock中调用row_quiesce_table_start来启动配置文件的生成。
</p><p><b>解决</b>
</p><p>移除断言
</p><p><a href="https://github.com/mysql/mysql-server/commit/a3f3c2ab7a1b985775f4e58529a4dd563c025b8e" class="external text" rel="nofollow">补丁</a>
</p><p><br />
<b>问题六</b>
</p><p>线上实例错误日志中偶尔出现 “UNABLE TO PURGE A RECORD”，从官方bug系统来看，很多用户都遇到了类似的问题。
</p><p>当change buffer模块以如下序列来缓存索引操作时可能产生上述错误信息：
</p>
<ol><li>记录被标记删除（IBUF_OP_DELETE_MARK）
</li><li>随后插入相同记录--IBUF_OP_INSERT
</li><li>Purge线程需要物理删除二级索引记录，操作被buffer--IBUF_OP_DELETE
</li></ol>
<p>当读入物理页时，总是需要进行ibuf merge。如果执行到IBUF_OP_DELETE这种类型的change buffer时，发现记录并没有被标记删除，就会导致错误日志报错。
</p><p>显然上述的操作序列是不合理的，正确的序列应该是IBUF_OP_DELETE_MARK，IBUF_OP_DELETE，IBUF_OP_INSERT。
</p><p>为了搞清楚逻辑，我们简单的理一下相关代码。
</p><p>注意IBUF_OP_DELETE是由第一步的标记删除操作触发，Purge线程发起；在每个buffer pool的控制结构体中，有一个成员buf_pool-&gt;watch[BUF_POOL_WATCH_SIZE]，BUF_POOL_WATCH_SIZE的值为purge线程个数，用于辅助Purge操作。
</p><p>假定内存中没有对应的Page，Purge线程会做如下几件事儿：
</p>
<ul><li>首先查询buffer pool，看看page是否已经读入内存；如果不在内存中，则将page no等信息存储到watch数组中，并插入page hash（buf_pool_watch_set）。（如果随后page被读入内存，也会删除watch标记）
</li></ul>
<ul><li>判断该二级索引记录是否可以被Purge（row_purge_poss_sec，当该二级索引记录对应的聚集索引记录没有delete mark并且其trx id比当前的purge view还旧时，不可以做Purge操作）
</li></ul>
<ul><li>随后在插入IBUF_OP_DELETE类型的ibuf记录时，还会double check下该page是否被设为sentinel （ibuf_insert_low，buf_pool_watch_occurred），如果未被设置，表明已经page已经读入内存，就可以直接去做purge，而无需缓存了。
</li></ul>
<ul><li>对于普通的操作类型，例如IBUF_OP_INSERT和IBUF_OP_DELETE_MARK，同样也会double check page 是否读入了内存。在函数ibuf_insert中会调用buf_page_hash_get进行检查，如果page被读入内存，则不缓存操作，如果请求的Page被设为sentinel，则从buf_page_hash_get返回NULL，因此随后判定需要缓存该类型的操作。这也正是问题的所在：
</li></ul>
<ol><li>标记删除记录，写入IBUF_OP_DELETE_MARK
</li><li>Purge线程设置page对应的sentinel，完成合法性检查，准备调用ibuf_insert
</li><li>插入相同记录，写入IBUF_OP_INSERT
</li><li>Purge线程写入IBUF_OP_DELETE
</li></ol>
<p><b>解决</b>
</p><p>如果记录所在的page被设置了一个sentinel，那么对该page的并发插入操作就不应该缓存到change buffer中，而是直接去尝试读取物理页。
</p><p><a href="https://github.com/mysql/mysql-server/commit/ec369cb4f363161dfbbbd662b20763b54808b7d1" class="external text" rel="nofollow">补丁</a>
</p><p><br />
<b>问题七</b>
</p><p>对于非windows系统的平台上，函数os_file_pwrite和os_file_pread在碰到io错误时返回-1，并错误的作为写入/读取的字节数写在错误日志中。
</p><p><b>解决</b>
</p><p>单独记录失败的系统调用日志，打印更可读的日志信息。
</p><p><a href="https://github.com/mysql/mysql-server/commit/ae0f4c17c82d1d3ee89ca5afb64655b4ab1d2552" class="external text" rel="nofollow">补丁</a>
</p><p><br />
<b>问题八</b>
</p><p>在崩溃恢复后立刻执行一次slow shutdown （innodb_fast_shutdown = 0） 可能产生断言失败crash。原因是当完成crash recovery后，对于需要回滚的事务，会起单独的线程来执行，这时候如果shutdown实例，会触发触发purge线程内部断言失败：ut_a(n_pages_purged == 0 || srv_fast_shutdown&nbsp;!= 0);
</p><p><b>解决</b>
</p><p>等待trx_rollback_or_clean_all_recovered完成后，再进行slow shutdown
</p><p><a href="https://github.com/mysql/mysql-server/commit/8edcc65fcd0c930a902cdf1c41ad0a1aaf21ff90" class="external text" rel="nofollow">补丁</a>
</p>
<h2> <span class="mw-headline" id="PgSQL_.C2.B7_.E7.89.B9.E6.80.A7.E5.88.86.E6.9E.90.C2.B7_Replication_Slot"> PgSQL ·  特性分析· Replication Slot </span></h2>
<p>PostgreSQL 9.4 已于2014年底正式发布了（阿里云的RDS将支持PG 9.4）。在这个版本，我们看到了像Jsonb, Logical Decoding, Replication Slot等新功能。对于Replication Slot，文档上介绍的不多，乍一看让人比较难理解是做什么的。其实，Replication Slot的出现，主要是为最终在PG内核实现逻辑复制和双向复制铺路的（目前，逻辑和双向复制在内核中还缺少很多核心功能点，需要借助BDR插件，见<a href="https://wiki.postgresql.org/wiki/BDR_Project" class="external text" rel="nofollow">PG官方wiki</a> ，引入Replication Slot的背后原因见<a href="http://blog.2ndquadrant.com/postgresql-9-4-slots/" class="external text" rel="nofollow">这里</a>）。不过，作为9.4版本的一个主要功能，它不但可以用于逻辑复制，还可用于物理复制（或者叫Streaming Replication）。针对物理复制的Replication Slot称为Physical Replication Slot。
</p><p>由于大家目前主要用的还只是PG自带的物理复制方式，我们就重点分析一下Physical Replication Slot。
</p><p>使用Physical Replication Slot，可以达到两个效果：
</p><p>A）可以确保从库（standby）需要的日志不被过早备份出去而导致从库失败，出现下面的error：
</p>
<pre>ERROR:  requested WAL segment 00000001000000010000002D has already been removed
</pre>
<p>通过Replication Slot记录的从库状态，PG会保证从库还没有apply的日志，不会从主库的日志目录里面清除或archive掉。而且，replication slot的状态信息是持久化保存的，即便从库断掉或主库重启，这些信息仍然不会丢掉或失效。
</p><p>B）当允许应用连接从库做只读查询时，Replication Slot可以与运行时参数hot_standby_feedback配合使用，使主库的vacuum操作不会过早的清掉从库查询需要的记录，而出现如下错误（错误的原因下面会详细解释）：
</p>
<pre>ERROR:  canceling statement due to conflict with recovery
</pre>
<p><br />
下面看看Physical Replication Slot的用法和内核实现。
</p><p><br />
<b>用法</b>
</p><p>下面是启用Replication Slot的步骤，很简单：
</p><p>1）首先需要配置好Steaming Replication的主库从库。涉及的参数有，listen_addresses（='*'），hot_standby（=on）， wal_level（=hot_standby），max_wal_senders（=1），尤其注意配置max_replication_slots大于等于1。这些参数主从库应一致。
</p><p>2）在主库创建replication slot：
</p>
<pre>postgres=# SELECT * FROM pg_create_physical_replication_slot('my_rep_slot_1');
  slot_name   | xlog_position
---------------+---------------
my_rep_slot_1 |
</pre>
<p>此时replication slot还不处于active状态。
</p><p>3)  在从库配置recovery.conf如下，然后重启从库：
</p>
<pre>standby_mode = 'on'
primary_slot_name = 'my_rep_slot_1'
primary_conninfo = 'user=pg001 host=10.x.x.x port=5432 sslmode=prefer sslcompression=1 krbsrvname=postgres'
</pre>
<p>4）观察主库replication slot的状态变化：
</p>
<pre>postgres=# SELECT * FROM pg_replication_slots&nbsp;;
  slot_name   | plugin | slot_type | datoid | database | active | xmin | catalog_xmin | restart_lsn
---------------+--------+-----------+--------+----------+--------+------+--------------+-------------
my_rep_slot_1 |        | physical  |        |          | t      | 1812 |              | 0/3011A70
</pre>
<p>5）与hot_standby_feedback配合使用。在将从库的postgresql.conf文件中的hot_standby_feedback选项设为on，重启从库即可。
</p><p><br />
<b>内核实现</b>
</p><p>replication slot是由下面的<a href="http://git.postgresql.org/gitweb/?p=postgresql.git;a=commit;h=858ec11858a914d4c380971985709b6d6b7dd6fc" class="external text" rel="nofollow">patch</a>加入内核中的：
</p>
<pre>author	Robert Haas &lt;rhaas@postgresql.org&gt;	
Sat, 1 Feb 2014 03:45:17 +0000 (22:45 -0500)
committer	Robert Haas &lt;rhaas@postgresql.org&gt;	
Sat, 1 Feb 2014 03:45:36 +0000 (22:45 -0500)
Replication slots are a crash-safe data structure which can be created
on either a master or a standby to prevent premature removal of
write-ahead log segments needed by a standby, as well as (with
hot_standby_feedback=on) pruning of tuples whose removal would cause
replication conflicts.  Slots have some advantages over existing
techniques, as explained in the documentation.
</pre>
<p>这个patch改的文件不少，分析这些代码，我们重点关注下面的问题：
</p><p>A）Replication Slot是如何在内核中创建的？
</p><p>通过分析创建Replication Slot时调用的函数ReplicationSlotCreate，可以看出，<b>Replication Slot实质上是内存中的一些数据结构，加上持久化保存到pg_replslot/&lt;slot name&gt;目录中的二进制状态文件。</b>在PG启动的时候，预先在共享内存中分配好这些数据结构所用内存（即一个大小为max_replication_slots的数组）。这些数据结构在用户创建Replication Slot时开始被使用。一个Replication Slot被创建并使用后，其数据结构和状态文件会被WAL（Write-Ahead-Log）的发送者（wal_sender)进程更新。
</p><p>另外，如果单纯从Replication Slot的名字，我们很容易觉得Replication Slot会创建新的与从库的连接，进行日志发送。实际上，创建过程中并没有创建新的与从库的连接，Replication Slot还是使用了wal_sender原有连接（由于一个从库一个wal_sender连接，所以一个从库和主库之间也只有一个active的Replication Slot）。
</p><p>B) Replication Slot的状态是如何被更新的？
</p><p>很容易发现，Replication Slot的状态的更新有两种情况。
</p><p>第一种是在ProcessStandbyHSFeedbackMessage这个函数被更新。这个函数是在处理wal_sender所收到的从库发回的feedback reply message时调用的。通过这个函数，我们可以看出，每个wal_sender进程的Replication Slot（就是用户创建的Replication Slot）保存在MyReplicationSlot这个全局变量中。在处理从库发回的reply时，reply中的xmin信息会被提取出来，存入slot的data.xmin和effective_xmin域中，并通过函数ProcArraySetReplicationSlotXmin，最终更新到系统全局的procArray-&gt;replication_slot_xmin结构中（以使其对所有进程可见），完成slot的更新。
</p><p>这里要注意，如果我们有多个Replication Slot（分别对应各自从库），则在更新全局结构procArray-&gt;replication_slot_xmin时，会选取所有slot中最小的xmin值。
</p><p>第二种是在ProcessStandbyReplyMessage中。这个函数处理从库发送的restart lsn信息（即从库apply的日志的编号），会直接将其更新到replication slot的restart lsn域中，并保存到磁盘，用于主库判断是否要保留日志不被archive。
</p><p>C) Replication Slot如何和hot_standby_feedback配合，来避免从库的查询冲突的？
</p><p>这里，从库的查询冲突指的是下面的情况：从库上有正在运行的查询，而且运行时间很长；这时主库上在做正常的vaccum，清除掉无用的记录版本。但主库的vaccum是不知道从库的查询存在的，所以在清除时，不考虑从库的正在运行的查询，只考虑主库里面的事务状态。其结果，vacuum可能会清除掉从库查询中涉及的，仍然在使用的记录版本。当这些vaccum操作，通过日志同步到从库，而恰好从库的查询仍然没有运行完，vaccum就要等待或cancel这个查询，以保证同步正常继续和查询不出现错误的结果。这样，每当用户在从库运行长查询，就容易出现我们上面提到到query conflict error。
</p><p>如何避免这种冲突呢？目前最好的解决方案是使用hot_standby_feedback + Replication Slot。其原理简单说就是，从库将它的查询所依赖的记录版本的信息，以一个事务id来表示，并放在从库发回给主库wal_sender的reply中发给主库（见函数XLogWalRcvSendHSFeedback），并最终传导给主库vaccum，让其刀下留人，暂时不清除相关记录。
</p><p>具体过程是，在从库，函数XLogWalRcvSendHSFeedback调用GetOldestXmin获得xmin，放入给主库的reply中。主库的wal_sender收到后，如果使用了Replication Slot，就把这个xmin放入slot的状态信息中，并更新此时系统所有slot的最小xmin。这个系统所有slot的最小xmin怎么在主库传导给vacuum的呢？以自动触发的vacuum操作为例，其中的逻辑的顺序如下：
</p><p>GetSnapshotData（vacuum事务开始时，获取slot xmin，存入全局变量）  -&gt;vacuum_set_xid_limits（调用 GetOldestXmin，通过全局变量，获取系统xmin和slot xmin，取较小值）-&gt; vacuum_lazy （使用xmin，判断哪些记录版本可以清除）
</p><p>这样，利用Replication Slot这个渠道，就解决了从库查询冲突。
</p><p><b>注意事项 </b>
</p><p>最后，介绍一下使用Replication Slot的注意事项：
</p><p>1）如果收不到从库的reply，Replication Slot的状态restart lsn会保持不变，造成主库会一直保留本地日志，可能导致日志磁盘满。所以应该实时监控日志磁盘使用情况，并设置较小的wal_sender_timeout，及早发现从库断掉的情况。
</p><p>2）将hot_standby_feedback设为on时，注意如果从库长时间有慢查询发生，可能导致发回到主库的xmin变化较慢，主库的vaccum操作停滞，造成主库被频繁更新的表大小暴增。
</p><p>除了物理复制，Replication Slot对逻辑复制的意义更大，我们期待在可能出现逻辑复制功能的9.5版本中看到它大显身手。
</p><p><br />
</p>
<h2> <span class="mw-headline" id="PgSQL_.C2.B7_.E7.89.B9.E6.80.A7.E5.88.86.E6.9E.90.C2.B7_pg_prewarm"> PgSQL ·  特性分析· pg_prewarm </span></h2>
<p>PostgreSQL内核中引入了一个很有意思的插件，pg_prewarm。它可以用于在系统重启时，手动加载经常访问的表到操作系统的cache或PG的shared buffer，从而减少检查系统重启对应用的影响。这个插件是这个通过这个<a href="http://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=c32afe53c2e87a56e2ff930798a5588db0f7a516" class="external text" rel="nofollow">patch</a>加入PG内核的。
pg_prewarm的开发者在设计pg_prewarm时，把它设计成一个执行单一任务的工具，尽求简单，所以我们看到的pg_prearm功能和实现都非常简单。下面我们对它进行性能实测并分析一下它的实现。
</p><p><br />
<b>基本信息</b>
</p><p>利用下面的语句可以创建此插件：
</p>
<pre>create EXTENSION pg_prewarm;
</pre>
<p>实际上，创建插件的过程只是用下面的语句创建了pg_prewarm函数。这个函数是此插件提供的唯一函数：
</p>
<pre>CREATE FUNCTION pg_prewarm(regclass,
        mode text default 'buffer',
        fork text default 'main',
        first_block int8 default null,
        last_block int8 default null)
RETURNS int8
AS 'MODULE_PATHNAME', 'pg_prewarm'
LANGUAGE C
    
</pre>
<p>函数的第一个参数是要做prewarm的表名，第二个参数是prewarm的模式（prefetch模式表示异步预取到操作系统cache；read表示同步预取；buffer则表示同步读入到PG的shared buffer），第三个参数是relation fork的类型（一般用main，其他类型有visibilitymap和fsm，参见<a href="https://github.com/postgres/postgres/blob/4baaf863eca5412e07a8441b3b7e7482b7a8b21a/src/include/common/relpath.h" class="external autonumber" rel="nofollow">[1]</a><a href="https://github.com/postgres/postgres/blob/b819dd7cb55aed1d607cef36b0ecd1a0642872b2/src/backend/storage/smgr/README" class="external autonumber" rel="nofollow">[2]</a>），最后两个参数是开始和结束的block number（一个表的block number从0开始，block总数可以通过pg_class系统表的relpages字段获得）。
</p><p><br />
<b>性能实测</b>
</p><p>再来看看，这个prewarm性能上能达到多大效果。我们先将PG的shared buffer设为2G，OS总的memory有7G。然后创建下面的大小近1G的表test：
</p>
<pre>pgbench=# \d test
       Table "public.test"
Column |     Type      | Modifiers
--------+---------------+-----------
 name   | character(20) |
</pre>
<pre>pgbench=#  SELECT pg_size_pretty(pg_total_relation_size('test'));
 pg_size_pretty
----------------
 995 MB
</pre>
<p>在每次都清掉操作系统cache和PG的shared buffer的情况下，分别测试下面几种场景：
</p><p>1）不进行pg_prewarm的情况：
</p>
<pre>pgbench=# explain analyze select count(*) from test;
                                                       QUERY PLAN
---------------------------------------------------------------------------------------------------------------------------
Aggregate  (cost=377389.91..377389.92 rows=1 width=0) (actual time=22270.304..22270.304 rows=1 loops=1)
  -&gt;  Seq Scan on test  (cost=0.00..327389.73 rows=20000073 width=0) (actual time=0.699..18287.199 rows=20000002 loops=1)
Planning time: 0.134 ms
Execution time: 22270.383 ms
</pre>
<p>可以看到，近1G的表，全表扫描一遍，耗时22秒多。
</p><p>2）下面我们先做read这种模式的prewarm，test表的数据被同步读入操作系统cache（pg_prewarm返回的是处理的block数目，此处我们没指定block number，也就是读入test的所有block），然后再做全表扫：
</p>
<pre>pgbench=# select pg_prewarm('test', 'read', 'main');
pg_prewarm
------------
    127389
</pre>
<pre>pgbench=# explain analyze select count(*) from test;
                                                       QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------
Aggregate  (cost=377389.90..377389.91 rows=1 width=0) (actual time=8577.767..8577.767 rows=1 loops=1)
  -&gt;  Seq Scan on test  (cost=0.00..327389.72 rows=20000072 width=0) (actual time=0.086..4716.444 rows=20000002 loops=1)
Planning time: 0.049 ms
Execution time: 8577.831 ms
</pre>
<p>时间降至8秒多！这时反复执行全表扫描，时间稳定在8秒多。
</p><p>3）再尝试buffer模式：
</p>
<pre>pgbench=# select pg_prewarm('test', 'buffer', 'main');
pg_prewarm
------------
    127389
</pre>
<pre>pgbench=# explain analyze select count(*) from test;
                                                       QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------
Aggregate  (cost=377389.90..377389.91 rows=1 width=0) (actual time=8214.277..8214.277 rows=1 loops=1)
  -&gt;  Seq Scan on test  (cost=0.00..327389.72 rows=20000072 width=0) (actual time=0.015..4250.300 rows=20000002 loops=1)
Planning time: 0.049 ms
Execution time: 8214.340 ms
</pre>
<p>比read模式时间略少，但相差不大。可见，如果操作系统的cache够大，数据取到OS cache还是shared buffer对执行时间影响不大（在不考虑其他应用影响PG的情况下）。
</p><p>4）最后尝试prefetch模式，即异步预取。这里，我们有意在pg_prewarm返回后，立即执行全表查询。这样在执行全表查询时，可能之前的预取还没完成，从而使全表查询和预取并发进行，缩短了总的响应时间：
</p>
<pre>explain analyze select pg_prewarm('test', 'prefetch', 'main');
                                       QUERY PLAN
------------------------------------------------------------------------------------------
Result  (cost=0.00..0.01 rows=1 width=0) (actual time=1011.338..1011.339 rows=1 loops=1)
Planning time: 0.124 ms
Execution time: 1011.402 ms
</pre>
<pre>explain analyze select count(*) from test;
                                                       QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------
Aggregate  (cost=377389.90..377389.91 rows=1 width=0) (actual time=8420.652..8420.652 rows=1 loops=1)
  -&gt;  Seq Scan on test  (cost=0.00..327389.72 rows=20000072 width=0) (actual time=0.065..4583.200 rows=20000002 loops=1)
Planning time: 0.344 ms
Execution time: 8420.723 ms
</pre>
<p>可以看到，总的完成时间是9秒多，使用pg_prewarm做预取大大缩短了总时间。因此在进行全表扫描前，做一次异步的prewarm，不失为一种优化全表查询的方法。
</p><p><br />
<b>实现</b>
</p><p>pg_prewarm的代码只有一个pg_prewarm.c文件。可以看出，prefetch模式下，对于表的每个block，调用一次PrefetchBuffer，后面的调用为：
</p>
<pre>PrefetchBuffer -&gt; smgrprefetch  -&gt; mdprefetch -&gt; FilePrefetch -&gt; posix_fadvise（POSIX_FADV_WILLNEED）
</pre>
<p>可见，它是最终调用posix_fadvise，把读请求交给操作系统，然后返回，实现的异步读取。
</p><p>而在read和buffer模式（调用逻辑分别如下）中，最终都调用了系统调用read，来实现同步读入OS cache和shared buffer的（注意buffer模式实际上是先读入OS cache，再拷贝到shared buffer）：
</p>
<pre>read模式：smgrread -&gt; mdread -&gt; FileRead  -&gt; read
</pre>
<pre>buffer模式：ReadBufferExtended -&gt; ReadBuffer_common -&gt; smgrread -&gt; mdread -&gt; FileRead -&gt; read
</pre>
<p><br />
<b>问题</b>
</p>
可能有人比较疑惑：执行1次select * from <table>不就可以将表的数据读入shared buffer和OS cache而实现预热了吗？岂不是比做这样一个插件更简单？实际上，对于较大的表（大小超过shared buff的1/4），进行全表扫描时，PG认为没必要为这种操作使用所有shared buffer，只会让其使用很少的一部分buffer，一般只有几百K，详细描述可以参见<a href="https://github.com/postgres/postgres/blob/4baaf863eca5412e07a8441b3b7e7482b7a8b21a/src/include/storage/bufmgr.h" class="external text" rel="nofollow">关于BAS_BULKREAD策略的代码</a>和<a href="https://github.com/postgres/postgres/tree/17792bfc5b62f42a9dfbd2ac408e7e71c239330a/src/backend/storage/buffer" class="external text" rel="nofollow">README</a>）。所以，预热大表是不能用一个查询直接实现的，而pg_prewarm正是在这方面大大方便了用户。

<h2> <span class="mw-headline" id="MySQL_.C2.B7_.E7.AD.94.E7.96.91.E9.87.8A.E6.83.91.C2.B7_InnoDB.E4.B8.A2.E5.A4.B1.E8.87.AA.E5.A2.9E.E5.80.BC">MySQL · 答疑释惑· InnoDB丢失自增值 </span></h2>
<p><b> 背景 </b>
</p><p>在上一期的月报中，我们在<a href="http://mysql.taobao.org/index.php/MySQL%E5%86%85%E6%A0%B8%E6%9C%88%E6%8A%A5_2015.01#MySQL_.C2.B7_.E6.8D.89.E8.99.AB.E5.8A.A8.E6.80.81.C2.B7_InnoDB.E8.87.AA.E5.A2.9E.E5.88.97.E9.87.8D.E5.A4.8D.E5.80.BC.E9.97.AE.E9.A2.98" class="external text" rel="nofollow">InnoDB自增列重复值问题</a> 中提到，InnoDB 自增列在重启后会丢失，因为MySQL没有持久化自增值，平时是存在内存表对象中的。如果实例重启的话，内存值丢失，其初始化过程是做了一个类似 select max(id) + 1 操作。实际上存在另外一种场景，实例即使不重启，也会导致自增值丢失。
</p><p><b> 问题说明 </b>
</p><p>实例运行过种中，InnoDB表自增值是存储在表对象中的，表对象又是放在缓存中的，如果表太多而不能全部放在缓存中的话，老的表就会被置换出来，这种被置换出来的表下次再使用的时候，就要重新打开一遍，对自增列来说，这个过程就和实例重启类似，需要 select max(id) + 1 算一下自增值。
</p><p>对InnoDB来说，其数据字典中表对象缓存大小由 <a href="http://dev.mysql.com/doc/refman/5.6/en/server-system-variables.html#sysvar_table_definition_cache" class="external text" rel="nofollow">table_definition_cache</a>  系统变量控制，在5.6.8之后，其最小值是400。和表缓存相关的另一个系统变量是<a href="http://dev.mysql.com/doc/refman/5.6/en/server-system-variables.html#sysvar_table_definition_cache" class="external text" rel="nofollow">table_open_cache</a>，这个控制的是所有线程打开表的缓存大小，这个缓存放在server层。
</p><p>下面我们用testcase的方式来给出InnoDB表对象对置换出的场景：
</p>
<pre> ##把 table_definition_cache 和 table_open_cache 都设为400
 SET GLOBAL table_definition_cache = 400;
 SET GLOBAL table_open_cache = 400;
 
 ## 创建500个InnoDB自增表，各插入一条数据，然后把自增改为100
 let $i=0;
 while($i &lt; 500)
 {
   --eval CREATE TABLE t$i(id INT NOT NULL AUTO_INCREMENT, name VARCHAR(30), PRIMARY KEY(id)) ENGINE=InnoDB;
   --eval INSERT INTO t$i(name) VALUES("InnoDB");
   --eval ALTER TABLE t$i AUTO_INCREMENT = 100;
   --inc $i
 }
 
 ## 最后400张表扫一遍
 let $i=100;
 while($i &lt; 500)
 {
   --eval SELECT * FROM t$i;
   --inc $i
 }
 
 ## 稍微sleep下，等mysqld把不用的表（t0..t99）换出
 sleep 5;
 
 ## 查看t1表自增
 SHOW CREATE TABLE t1;
 
 Table   Create Table
 t1      CREATE TABLE `t1` (
   `id` int(11) NOT NULL AUTO_INCREMENT,
   `name` varchar(30) DEFAULT NULL,
   PRIMARY KEY (`id`)
 ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=latin1
 ...
</pre>
<p>可以看到自增值确实和重启场景一样，本应是100，却变成了 2（select max(id) + 1）了。
</p><p><br />
<b> 问题分析 </b>
</p><p>原因就是缓存不够，导致表对象被换出，下次再用就要重新打开，这里给出调用栈，对代码感兴趣的同学可以看下。
</p><p>将老的table置换出：
</p>
<pre> #0  dict_table_remove_from_cache_low (table=0x2b81d054e278, lru_evict=1)
     at /path/to/mysql/storage/innobase/dict/dict0dict.cc:1804
 #1  0x00000000011cf246 in dict_make_room_in_cache (max_tables=400, pct_check=100)
     at /path/to/mysql/storage/innobase/dict/dict0dict.cc:1261
 #2  0x0000000001083564 in srv_master_evict_from_table_cache (pct_check=100)
     at /path/to/mysql/storage/innobase/srv/srv0srv.cc:2017
 #3  0x0000000001084022 in srv_master_do_idle_tasks () at /path/to/mysql/storage/innobase/srv/srv0srv.cc:2212
 #4  0x000000000108484a in srv_master_thread (arg=0x0) at /path/to/mysql/storage/innobase/srv/srv0srv.cc:2360
 #5  0x00000030cc007851 in start_thread () from /lib64/libpthread.so.0
 #6  0x00000030cbce767d in clone () from /lib64/libc.so.6
</pre>
<p>尝试从缓存加载表对象： 
</p>
<pre> #0  dict_table_check_if_in_cache_low (table_name=0x2adef847db20 "test/t1")
     at /path/to/mysql/storage/innobase/include/dict0priv.ic:114
 #1  0x00000000011cd51a in dict_table_open_on_name (table_name=0x2adef847db20 "test/t1", dict_locked=0, try_drop=1,
     ignore_err=DICT_ERR_IGNORE_NONE) at /path/to/mysql/storage/innobase/dict/dict0dict.cc:947
 #2  0x0000000000e58d8a in ha_innobase::open (this=0x2adef9747010, name=0x2adef7460780 "./test/t1", mode=2, test_if_locked=2)
     at /path/to/mysql/storage/innobase/handler/ha_innodb.cc:4776
 #3  0x000000000068668b in handler::ha_open (this=0x2adef9747010, table_arg=0x2adef742bc00, name=0x2adef7460780 "./test/t1", mode=2,
     test_if_locked=2) at /path/to/mysql/sql/handler.cc:2525
 ...
 #9  0x00000000009c2a84 in mysqld_show_create (thd=0x2adef47aa000, table_list=0x2adef74200f0)
     at /path/to/mysql/sql/sql_show.cc:867
 #10 0x00000000009553b1 in mysql_execute_command (thd=0x2adef47aa000) at /path/to/mysql/sql/sql_parse.cc:3507
 #11 0x0000000000963bbe in mysql_parse (thd=0x2adef47aa000, rawbuf=0x2adef7420010 "show create table t1", length=20,
     parser_state=0x2adef8480630) at /path/to/mysql/sql/sql_parse.cc:6623
 ...
</pre>
<p>缓存加载不到表对象，用select maxt 逻辑初始化自增：
</p>
<pre> #0  row_search_max_autoinc (index=0x2b241d8f50f8, col_name=0x2b241d855519 "id", value=0x2b241e87d8a8)
     at /path/to/mysql/storage/innobase/row/row0sel.cc:5361
 #1  0x0000000000e58998 in ha_innobase::innobase_initialize_autoinc (this=0x2b241fbd9010)
     at /path/to/mysql/storage/innobase/handler/ha_innodb.cc:4663
 #2  0x0000000000e59bd9 in ha_innobase::open (this=0x2b241fbd9010, name=0x2b241d853780 "./test/t1", mode=2, test_if_locked=2)
     at /path/to/mysql/storage/innobase/handler/ha_innodb.cc:5089
 #3  0x000000000068668b in handler::ha_open (this=0x2b241fbd9010, table_arg=0x2b241e422000, name=0x2b241d853780 "./test/t1", mode=2,
     test_if_locked=2) at /path/to/mysql/sql/handler.cc:2525
 ...
 #9  0x00000000009c2a84 in mysqld_show_create (thd=0x2b241abaa000, table_list=0x2b241d8200f0)
     at /path/to/mysql/sql/sql_show.cc:867
 #10 0x00000000009553b1 in mysql_execute_command (thd=0x2b241abaa000) at /path/to/mysql/sql/sql_parse.cc:3507
 #11 0x0000000000963bbe in mysql_parse (thd=0x2b241abaa000, rawbuf=0x2b241d820010 "show create table t1", length=20,
     parser_state=0x2b241e880630) at /path/to/mysql/sql/sql_parse.cc:6623
 ...
</pre>
<p><b> 处理建议 </b>
</p><p>对于这个问题，一种解决方法是从源码改进，将自增值持久化，可以参考<a href="http://mysql.taobao.org/index.php/MySQL%E5%86%85%E6%A0%B8%E6%9C%88%E6%8A%A5_2015.01#MySQL_.C2.B7_.E6.8D.89.E8.99.AB.E5.8A.A8.E6.80.81.C2.B7_InnoDB.E8.87.AA.E5.A2.9E.E5.88.97.E9.87.8D.E5.A4.8D.E5.80.BC.E9.97.AE.E9.A2.98" class="external text" rel="nofollow">上期的月报</a>给出的思路；如果不想改代码的话，可以这样绕过：在设定auto_increment值后，主动插入一行记录，这样不论在重启还是缓存淘汰的情况下，重新打开表仍能得到预期的值。
</p><p><br />
</p>
<h2> <span class="mw-headline" id="MySQL_.C2.B7_.E7.AD.94.E7.96.91.E9.87.8A.E6.83.91.C2.B7_5.5_.E5.92.8C_5.6_.E6.97.B6.E9.97.B4.E7.B1.BB.E5.9E.8B.E5.85.BC.E5.AE.B9.E9.97.AE.E9.A2.98">MySQL · 答疑释惑· 5.5 和 5.6 时间类型兼容问题 </span></h2>
<p><b>问题描述</b>
</p><p>5.6.4及以上版本，datetime,time,timestamp的Binlog在5.6.4以下的备库无法执行，如：
</p><p>5.6.16（主库）: create table t1(t datetime default now());   insert into t1 values(now());
</p><p>5.5.18（备库）: show slave stauts\G&nbsp;;
</p><p>此时备库中断，报错：Last_Errno: 1677，
</p><p>描述信息：Last_Error: Column 1 of table t1.t' cannot be converted from type '&lt;unknown type&gt;' to type 'datetime'
</p><p>详情见<a href="http://bugs.mysql.com/bug.php?id=70085" class="external text" rel="nofollow">Bug#70085</a>
</p><p><b>问题原因</b>
</p><p>1) 5.5版本存储的是datetime,time,timestamp这三种数据类型的长整型的数据，insert时的BT为：
</p>
<pre>#0 TIME_to_ulonglong_datetime (my_time=0x2ad2c82e84c0) at /u01/workplace/Percona-Server-5.5.18/sql-common/my_time.c:1187
#1 0x0000000000680b6d in Field_datetime::store (this=0x2ad2d000fb10, from=0x2ad2d0014fe0 "2014-02-25 11:20:42", len=19, cs=&lt;value optimized out&gt;) 
#2 0x00000000005488a4 in fill_record (thd=0xa602190, ptr=&lt;value optimized out&gt;, values=&lt;value optimized out&gt;, ignore_errors=&lt;value optimized out&gt;, triggers=0x0, event) 
#3 fill_record_n_invoke_before_triggers (thd=0xa602190, ptr=&lt;value optimized out&gt;, values=&lt;value optimized out&gt;, ignore_errors=&lt;value optimized out&gt;, triggers=0x0, event)
</pre>
<p>2) 5.6.16的相应堆栈为：
</p>
<pre>#0 my_datetime_packed_to_binary (nr=1842590951223066624, ptr=0x7fa88005dea1 "\231\222\062\265*", dec=0)
#1 0x00000000009155d4 in Field_datetimef::store_packed (this=0x7fa88005dec0, nr=1842590951223066624)
#2 0x000000000091553a in Field_datetimef::store_internal (this=0x7fa88005dec0, ltime=0x7fa8d42018f0, warnings=0x7fa8d4201920)
#3 0x000000000091191a in Field_temporal_with_date::store_internal_with_round (this=0x7fa88005dec0, ltime=0x7fa8d42018f0,warnings=0x7fa8d4201920) 
#4 0x00000000009109e9 in Field_temporal::store (this=0x7fa88005dec0, str=0x7fa8800052f8 "2014-02-25 11:20:42", len=19, cs=0x168e400)
#5 0x000000000065360b in Item::save_str_value_in_field (this=0x7fa880005310, field=0x7fa88005dec0, result=0x7fa880005320)
#6 0x0000000000663ef6 in Item_string::save_in_field (this=0x7fa880005310, field=0x7fa88005dec0, no_conversions=false)
#7 0x000000000077bbc6 in fill_record (thd=0x6f24020, ptr=0x7fa88005deb8, values=..., ignore_errors=false, bitmap=0x0)
#8 0x000000000077bcf7 in fill_record_n_invoke_before_triggers (thd=0x6f24020, ptr=0x7fa88005deb0, values=..., ignore_errors=false,triggers=0x0, event)
</pre>
<p>从面的两个堆栈可以看出，在构造插入数据的时候，调用的是Field的具体函数，根据不同类型调用的方法不同；5.5与5.6之间，datetime的数据类型不一致，当5.5升级到5.6时，其堆栈不变，原因是在表的FRM中，记录了表中列的数据类型，其中5.5中的数据类型为MYSQL_TYPE_DATETIME，5.6的数据类型为MYSQL_TYPE_DATETIME2，所以对于原表升级，不影响复制，但是对于新表中如果含有这三种数据类型的表，复制到备库就会出现问题，因为5.5中，没有MYSQL_TYPE_DATETIME2这种数据类型。
</p><p><b> 解决方法</b>
</p><p>对表的DML操作或DDL操作，都是依赖于表结构而言的，这也是为什么物理5.5升级到5.6后，对于原本含有datetime,time,timestamp这三种类型的表没有影响，但是对于新建的表就会有影响，原因就是对于产生Binlog的操作或存储引擎的操作的Field来源于FRM文件，所以，当在创建表的时候，如果5.5要使用5.6的Binlog，那我们对于DDL含有这三种数据类型的操作，使用5.5可以识别的数据类型：MYSQL_TYPE_DATETIME，而不是MYSQL_TYPE_DATETIME2，这样在MySQL内部的操作过程中就不会有问题，因此我们可以为MySQL添加一个参数，当参数打开时，创建datetime,time,timestamp的数据类型为兼容5.5的数据类型，否则为新的数据类型。
</p><p><b> TimeStamp 与 Datetime 的区别 </b>
</p><p>1. 值域不同
</p><p>TIMESTAMP has a range of '1970-01-01 00:00:01' UTC to '2038-01-19 03:14:07' UTC. DATETIME  The supported range is '1000-01-01 00:00:00' to '9999-12-31 23:59:59'
TimeStamp带有时区信息，其中TimeStamp在存储时，将当前时间转化为UTC格式的时间，如北京时间，现在是2014-03-15 23:21:00,那么存储的会是2014-03-15 23:21:00 - 3600S；取数据的时候会加上当前时区时间。
</p><p>2. 底层的存储结构不同
</p><p>5.5 是以longlong类型存储的，而5.6 的格式如下：
</p><p>timestamp：4+max(3); (变长，4-7个字节)，没有Sign
</p><p>datetime： 底层存储(变长，5-8个字节)
</p>
<pre>1 bit  sign            (used when on disk)
  17 bits year*13+month   (year 0-9999, month 0-12)
   5 bits day             (0-31)
   5 bits hour            (0-23)
   6 bits minute          (0-59)
   6 bits second          (0-59)
  24 bits microseconds    (0-999999)
  Total: 64 bits = 8 bytes
</pre>
<p><br />
</p>
<h2> <span class="mw-headline" id="MySQL_.C2.B7_.E6.8D.89.E8.99.AB.E5.8A.A8.E6.80.81.C2.B7_.E5.8F.98.E9.87.8F.E4.BF.AE.E6.94.B9.E5.AF.BC.E8.87.B4binlog.E9.94.99.E8.AF.AF"> MySQL · 捉虫动态·  变量修改导致binlog错误 </span></h2>
<p><b> 背景 </b>
</p><p>MySQL 5.6.6 版本新加了这样一个参数——log_bin_use_v1_row_events，这个参数用来控制binlog中Rows_log_event的格式，如果这个值为1的话，就用v1版的Rows_log_event格式（即5.6.6之前的），默认是0，用新的v2版本的格式，更详细看<a href="http://dev.mysql.com/doc/refman/5.6/en/replication-options-binary-log.html#sysvar_log_bin_use_v1_row_events" class="external text" rel="nofollow">官方文档</a>。这个参数一般保持默认即可，但是当我们需要搭 5.6-&gt;5.5 这要的主备的时候，就需要把主库的这个值改为1，不然5.5的备库不能正确解析Rows_log_event。最近在使用这个参数的时候发现了一个bug，导致主库binlog写坏，备库复制中断，报错如下：
</p><p>Last_SQL_Errno: 1594
Last_SQL_Error: Relay log read failure: Could not parse relay log event entry. The possible reasons are: the master's binary log is corrupted (you can check this by running 'mysqlbinlog' on the binary log), the slave's relay log is corrupted (you can check this by running 'mysqlbinlog' on the relay log), a network problem, or a bug in the master's or slave's MySQL code. If you want to check the master's binary log or slave's relay log, you will be able to know their names by issuing 'SHOW SLAVE STATUS' on this slave.
</p><p><b> bug 分析 </b>
</p><p>binlog event 结构
</p>
<pre>event header
event body
  -fixed part(postheader)
  -variable part (payload)
</pre>
<p>如上所示，每种binlog event 都可以分为header 和 body 2部分，body 又可以分为 fixed part 和 variable part，其中event header的长度相同并且固定，5.0开始用的v4格式的binlog，其event header固定长度为19字节，包含多个字段，具体每个字段的含义可以看<a href="http://dev.mysql.com/doc/internals/en/event-structure.html" class="external text" rel="nofollow">这里</a>。 event body 中post header 长度也是固定的，所以叫 fixed part，但是不同类型event这一部分的长度不一样，最后的 variable part 就是event的主体了，这个就长度不一了。 log_bin_use_v1_row_events 这个值的不同，影响的部分就是 postheader 这里的长度，如果值为1的话，用v1格式，postheader 长度是8个字节，如果是0，用v2格式，其长度为10。每个Rows_log_event的event header的type字节会标明当前event是v1还是v2，试想一下，如果event header部分标明是v2，postheader却实际上只有8个字节，或者反过来，event header部分标明是v1，postheader有10个字节，备库拿到这样的binlog，去尝试解析的时候，就完全凌乱了。
</p><p>为啥会出现这种一个event前后不一致的情况呢，代码编写不严谨！
</p><p>在写 Rows_log_event(Write/Update/Delete)  过程中，有2次用到 log_bin_use_v1_row_events 这个全局变量，一次是在构造函数处，一次是在写postheader时 Rows_log_event::write_data_header()，2次都是直接使用，如果正好在这2次中间，我们执行 set global log_bin_use_v1_row_events  = 0|1，改变原来的值，就会导致前后逻辑判断结果不一致。如果主库有频繁的更新操作，每次更新又比较大，只要修改这个值，就很容易触发这个bug。
</p><p>另外官方还有点不严谨的是，<a href="http://dev.mysql.com/doc/refman/5.6/en/replication-options-binary-log.html#sysvar_log_bin_use_v1_row_events" class="external text" rel="nofollow">文档上</a>说这个值是 readonly的，实际代码是dynamic 的，如果是 readonly 的话，也就不会触发上面的bug了。
</p><p><br />
<b> bug修复 </b>
</p><p>修复很简单，把2次引用全局变量改成一次就好了，在Rows_log_event::write_data_header函数里直接使用已经保存的m_type，改法如下
</p>
<pre>-  if (likely(!log_bin_use_v1_row_events))
+
+
+  if (likely(!(m_type == WRITE_ROWS_EVENT_V1 ||
+               m_type == UPDATE_ROWS_EVENT_V1 ||
+               m_type == DELETE_ROWS_EVENT_V1 )))
</pre>
<p>这样改之后，就只会在构造函数中才用到全局变量。
</p><p><br />
</p>
<h2> <span class="mw-headline" id="MariaDB_.C2.B7_.E7.89.B9.E6.80.A7.E5.88.86.E6.9E.90.C2.B7_.E8.A1.A8.2F.E8.A1.A8.E7.A9.BA.E9.97.B4.E5.8A.A0.E5.AF.86"> MariaDB ·  特性分析· 表/表空间加密 </span></h2>
<p>Google向MariaDB 10.1.13（暂未Release）贡献了这个补丁，可以对表/表空间进行加密。
</p><p>加密过的表可以防止某些非授权用户访问或偷取磁盘然后通过访问原始数据文件来偷取数据。当然，假设你已经把密钥文件存储在另一个系统上。但是，使用加密可能会降低差不多10%的性能。目前，只有XtraDB/InnoDB引擎能完全支持加密。
</p><p>MariaDB在InnoDB/XtraDB中支持两种方式的加密:
</p><p>Table encryption（表级加密）: 只有在创建时指定 PAGE_ENCRYPTION=1 的表才被加密。
</p><p>Tablespace encryption（表空间加密）: 当前实例下的任何文件都被加密（包括日志文件）。
</p><p>MariaDB中所有的加密算法都是基于AES的。但是你可以在启动的时候使用 --encryption-algorithm=name 来指定具体哪种基于AES的加密算法，有这些可选:
</p>
<table align="center" border="1">
<tr>
<td>选项
</td><td>描述
</td></tr>
<tr>
<td>none
</td><td>默认值。不进行任何加密。
</td></tr>
<tr>
<td>aes_cbc
</td><td>建议值。这是大部分欧洲政府接受的算法。
</td></tr>
<tr>
<td>aes_ctr
</td><td>一种新的块加密模式，Google自己开发的，并且在他们的MariaDB实例中使用的算法。
</td></tr>
<tr>
<td>aes_ecb
</td><td>这种加密模式用于内部计数器计算。你可以用它来加密，但它不能提供强保密性。
</td></tr></table>
<p><br />
<b>密钥的管理</b>
</p><p>为了保护加密过的数据，密钥必须另外保存，不要跟数据文件放在一个地方。默认情况下，MariaDB支持两种密钥管理方式，都是以Plugin的方式实现的。
</p><p>1） file_key_management_plugin
</p><p>file_key_management_plugin 是一个密钥管理插件，可以从文件中读取密钥。这个插件有如下配置选项：
</p><p>file_key_management_plugin_filename=path-to-key-file: 密钥文件存放的位置
</p><p>file_key_management_plugin_filekey: 一个可选的Key，用来解密密钥文件
</p><p>一个my.cnf配置的例子:
</p>
<pre>[mysqld]
encryption-algorithm = aes_cbc
file_key_management_plugin_filename = /home/mdb/keys.enc
file_key_management_plugin_filekey = secret
</pre>
<p>这个密钥文件（/home/mdb/keys.enc）包含了AES密钥。128, 192 或 256位密钥都可以支持。ID有16个字节。
一个密钥文件内容的例子如下：
</p>
<pre>1;F5502320F8429037B8DAEF761B189D12;770A8A65DA156D24EE2A093277530142
</pre>
<p>1是密钥的标识，在建表的时候可以指定使用哪个密钥; 接着是16字节的ID，最后是一个16字节的AES密钥。密钥标识可以从0~255，但是0号密钥是保留给InnoDB日志文件使用的，不要在建表的时候用。
</p><p>密钥文件本身同样可以加密，file_key_management_plugin_filekey定义的密钥可以用来解密密钥文件。OpenSSL命令行工具可以用来创建密钥文件。例如：
</p>
<pre>openssl enc –aes-256-cbc –md sha1 –k secret –in keys.txt –out keys.enc
openssl enc –aes-256-cbc –md sha1 –k &lt;initialPwd&gt; –in secret –out secret.enc
</pre>
<p>如果密钥文件在启动的时候读取不到（例如没提供解密密钥文件的Key），那么加密功能不再被支持，也无法访问被加密过的表。
</p><p><br />
2） example_key_management_plugin
</p><p>为了获得真正高强度的加密，密钥必须周期性的变更。
</p><p>example_key_management_plugin 是一个实现的例子。用你自己的密钥管理系统替换这个插件，可以创建一个非常安全的系统，例如从远程服务器来获取密钥。Google内部就是这么做的。
</p><p>当然，example_key_management_plugin 仅仅是一个例子，你要根据它来编写你自己的Plugin！
</p><p><b>加密数据</b>
</p><p>1）表级加密
</p><p>表级加密意味着你可以选择哪些表需要加密。这可以让你在速度和安全性之间获得平衡。
</p><p>要使用表级加密，你要这样做:
</p>
<ul><li> 设置 encryption-algorithm 选择你需要的加密算法；
</li><li> 载入 file-key-management-plugin 插件或者其他相似的插件，添加 enable-file-key-management-plugin 到你的my.cnf文件。
</li></ul>
<p>要加密一个表，你需要在CREATE/ALTER TABLE 语句中使用新的参数：
</p>
<table align="center" border="1">
<tr>
<td>选项
</td><td>可选值
</td><td>描述
</td></tr>
<tr>
<td>PAGE_ENCRYPTION
</td><td>0 或 1
</td><td>1是启用这个功能，0是关闭
</td></tr>
<tr>
<td>PAGE_ENCRYPTION_KEY
</td><td>0-255
</td><td>密钥表示。这个值表示用那个密钥。
</td></tr></table>
<p>例如：
</p>
<pre>CREATE TABLE T (id int, value varchar(255)) PAGE_ENCRYPTION=1 PAGE_ENCRYPTION_KEY=17;
</pre>
<p>这个建表语句会创建一个表T，使用标识为17的密钥加密。
</p>
<pre>ALTER TABLE T PAGE_ENCRYPTION=1 PAGE_ENCRYPTION_KEY=18;
</pre>
<p>更改表T使用标识为18的密钥来加密。如果你之前加密过这张表，那会首先解密这张表再重新加密。
</p>
<pre>ALTER TABLE T page_encryption=0;
</pre>
<p>关闭表T的加密功能。如果之前是加密的，那这个操作会做解密。
</p><p><br />
2） 表空间加密
</p><p>要使用加密表空间，需要这样做:
</p>
<ul><li> 设置 encryption-algorithm 来选择加密算法；
</li><li> 设置 innodb-encrypt-tables 为 1；
</li><li> 载入 file-key-management-plugin 插件或者其他相似的插件，添加 enable-file-key-management-plugin 到你的 my.cnf 文件；
</li><li> 启用 innodb-tablespaces-encryption 插件；
</li><li> 启用 innodb-tablespaces-scrubbing 插件。
</li></ul>
<p>有下列变量可以配置加密项：
</p>
<table align="center" border="1">
<tr>
<td>变量
</td><td>可选值
</td><td>描述
</td></tr>
<tr>
<td>innodb-encrypt-tables
</td><td>Boolean (0 or 1)
</td><td>是否在存储引擎加密所有表
</td></tr>
<tr>
<td>innodb-encryption-rotate-key-age
</td><td>秒数
</td><td>如果获取到了新密钥多久更新一次页面加密
</td></tr>
<tr>
<td>innodb-encryption-rotation-iop
</td><td>IOPS数
</td><td>后台使用多少IOPS来做页面加密更新
</td></tr>
<tr>
<td>innodb-encryption-threads
</td><td>线程数
</td><td>用多少个后台线程来做页面加密更新和清理
</td></tr>
<tr>
<td>innodb-background-scrub-data-check-interval
</td><td>秒数
</td><td>隔多久检查空间是否需要清理
</td></tr>
<tr>
<td>innodb-background-scrub-data-compressed
</td><td>Boolean (0 or 1)
</td><td>打开通过后台线程来清理压缩数据
</td></tr>
<tr>
<td>innodb-background-scrub-data-interval
</td><td>秒数
</td><td>隔多久调用一次清理
</td></tr>
<tr>
<td>innodb-background-scrub-data-uncompressed
</td><td>Boolean (0 or 1)
</td><td>打开通过后台线程来清理未压缩数据
</td></tr></table>
<p>清理（Scrubbing）意味着有一个后台线程定期的扫描所有的表并且对所有页面升级压缩密钥。
</p><p>配置表空间加密的示例 my.cnf:
</p>
<pre>[mysqld]
encryption-algorithm=aes_ctr
innodb-tablespaces-encryption
innodb-tablespaces-scrubbing
innodb-encrypt-tables
innodb-encryption-threads=4
</pre>
<p><b>加密和压缩</b>
</p><p>加密和压缩（配合FusionIO使用的功能，<a href="http://mysql.taobao.org/index.php/MySQL%E5%86%85%E6%A0%B8%E6%9C%88%E6%8A%A5_2014.08#MariaDB.C2.B7.E5.88.86.E6.94.AF.E7.89.B9.E6.80.A7.C2.B7FusionIO.E7.89.B9.E6.80.A7.E6.94.AF.E6.8C.81" class="external text" rel="nofollow">之前的月报介绍过</a>）可以同时使用。这可以让MariaDB先压缩数据然后再做加密，这种情况下可以很大的节省存储空间，并且数据更难被解密。
</p>
<h2> <span class="mw-headline" id="MariaDB_.C2.B7_.E7.89.B9.E6.80.A7.E5.88.86.E6.9E.90.C2.B7_Per-query_variables"> MariaDB ·  特性分析· Per-query variables </span></h2>
<p>自MariaDB 10.1.2起，MariaDB提供了一种"Per-query variables的方式来为Query设置语句级变量，通过 SET STATEMENT 语句可以为接下来要执行的语句设置一些系统变量值。
</p><p><br />
<b>语法</b>
</p><p>SET STATEMENT var1=value1 [, var2=value2, ...] FOR &lt;statement&gt;
</p><p>varN是一个系统变量，valueN是一个常量值。但是有部分变量是不支持的，在这个章节的末尾列出了所有不支持的变量。
</p><p>一条 "SET STATEMENT var1=value1 FOR stmt" 语句等价与如下一系列操作：
</p><p>SET @save_value=@@var1;
</p><p>SET SESSION var1=value1;
</p><p>stmt;
</p><p>SET SESSION var1=@save_value;
</p><p>MySQL服务器在执行整条语句前会先做解析，所以所有影响解析器的变量都无法达到预期的效果，因为解析完之后才能获得这些变量的值。例如字符集变量sql_mode=ansi_quotes。
</p><p><br />
<b>一些使用特性的例子</b>
</p><p>可以限制语句的执行时间 max_statement_time: SET STATEMENT max_statement_time=1000 FOR SELECT ...&nbsp;;
</p><p>为一个语句临时改变优化器的规则: SET STATEMENT optimizer_switch='materialization=off' FOR SELECT ....;
</p><p>为一个语句单独打开MRR/BKA特性: SET STATEMENT  join_cache_level=6, optimizer_switch='mrr=on' FOR SELECT ...
</p><p><br />
<b>下面这些变量无法使用Per-query variables特性来设置</b>
</p><p>autocommit
</p><p>character_set_client
</p><p>character_set_connection
</p><p>character_set_filesystem
</p><p>collation_connection
</p><p>default_master_connection
</p><p>debug_sync
</p><p>interactive_timeout
</p><p>gtid_domain_id
</p><p>last_insert_id
</p><p>log_slow_filter
</p><p>log_slow_rate_limit
</p><p>log_slow_verbosity
</p><p>long_query_time
</p><p>min_examined_row_limit
</p><p>profiling
</p><p>profiling_history_size
</p><p>query_cache_type
</p><p>rand_seed1
</p><p>rand_seed2
</p><p>skip_replication
</p><p>slow_query_log
</p><p>sql_log_off
</p><p>tx_isolation
</p><p>wait_timeout
</p>
<h2> <span class="mw-headline" id="TokuDB_.C2.B7_.E7.89.B9.E6.80.A7.E5.88.86.E6.9E.90.C2.B7_.E6.97.A5.E5.BF.97.E8.AF.A6.E8.A7.A3"> TokuDB ·  特性分析· 日志详解 </span></h2>
<p>TokuDB的日志跟InnoDB不一样，它有两类文件:   
</p>
<ol><li> redo-log文件(以.tokulog[序号]为扩展名)
</li><li> rollback日志文件(tokudb.rollback)
</li></ol>
<p>接下来就简单唠唠这两类文件的内部细节。
</p><p><b> 1) redo-log</b> 
</p><p>记录的不是页而是对Fractal-Tree索引的操作日志。   
log格式:
</p>
<pre>| length | command | lsn | content | crc|
</pre>
<p>content里记录的是具体的日志内容，比如insert操作，content就是:
</p>
<pre>| file-no | txnid | key | value|
</pre>
<p>TokuDB在做恢复的时候，会找到上次checkpoint时的LSN位置，然后读取log逐条恢复。
</p><p>为了确保log的安全性，redo-log也支持从后往前解析。  
</p><p>当一个log的MAX_LSN小于已完成checkpoint的LSN时，就表明这个log文件可以安全删除了。  
</p><p>那么问题来了： 
</p><p>如果用户执行了一个“大事务”，比如delete一个大表，耗时很长，log文件岂不是非常多，一直等到事务提交再做清理？
</p><p>不用的，这就是tokudb.rollback的作用了。
</p><p><b> 2) tokudb.rollback</b> 
</p><p>用户的事务操作(insert/delete/update写操作)都会写一条日志到tokudb.rollback，存储的格式是:
</p>
<pre>|txnid | key|
</pre>
<p>记录日志伪码如下：
</p>
<pre>void ft_insert(txn,...)
{
   if (txn) {
       toku_logger_save_rollback_cmdinsert(...);
   }

   if (do_logging &amp;&amp; logger) {
       toku_log_enq_insert(....);
   }
}
</pre>
<p>如果是事务，每个操作会写2条日志(1条redo，1条rollback)。
</p><p>如果用户执行了commit/rollback，TokuDB会根据txnid在tokudb.rollback里查到key(如果该entry不在cache里)，再根据key在索引文件里找到相应的事务信息并做相应的commit/rollback操作。 
</p>
tokudb.rollback可以看做是一个事务的undo日志，记录的是&lt;txnid，key&gt;的关系映射。</table>

<!-- 
NewPP limit report
Preprocessor node count: 41/1000000
Post-expand include size: 0/2097152 bytes
Template argument size: 0/2097152 bytes
Expensive parser function count: 0/100
-->

<!-- Saved in parser cache with key tmysqlwikidb-tmysql:pcache:idhash:135-0!1!0!!zh-cn!2!edit=0 and timestamp 20170515063800 -->
<div class="printfooter">
取自“<a href="http://mysql.taobao.org/index.php?title=MySQL%E5%86%85%E6%A0%B8%E6%9C%88%E6%8A%A5_2015.02">http://mysql.taobao.org/index.php?title=MySQL%E5%86%85%E6%A0%B8%E6%9C%88%E6%8A%A5_2015.02</a>”</div>
		<div id='catlinks' class='catlinks catlinks-allhidden'></div>		<!-- end content -->
				<div class="visualClear"></div>
	</div>
</div></div>
<div id="column-one">
	<div id="p-cactions" class="portlet">
		<h5>查看</h5>
		<div class="pBody">
			<ul>
				 <li id="ca-nstab-main" class="selected"><a href="/index.php?title=MySQL%E5%86%85%E6%A0%B8%E6%9C%88%E6%8A%A5_2015.02" title="查看页面内容 [c]" accesskey="c">页面</a></li>
				 <li id="ca-talk" class="new"><a href="/index.php?title=%E8%AE%A8%E8%AE%BA:MySQL%E5%86%85%E6%A0%B8%E6%9C%88%E6%8A%A5_2015.02&amp;action=edit&amp;redlink=1" title="关于页面正文的讨论 [t]" accesskey="t">讨论</a></li>
				 <li id="ca-viewsource"><a href="/index.php?title=MySQL%E5%86%85%E6%A0%B8%E6%9C%88%E6%8A%A5_2015.02&amp;action=edit" title="此页面已被保护，你可以查看其源代码。 [e]" accesskey="e">查看源代码</a></li>
				 <li id="ca-history"><a href="/index.php?title=MySQL%E5%86%85%E6%A0%B8%E6%9C%88%E6%8A%A5_2015.02&amp;action=history" title="此页面的早前修订版本 [h]" accesskey="h">历史</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-personal">
		<h5>个人工具</h5>
		<div class="pBody">
			<ul>
				<li id="pt-login"><a href="/index.php?title=%E7%89%B9%E6%AE%8A:%E7%94%A8%E6%88%B7%E7%99%BB%E5%BD%95&amp;returnto=MySQL%E5%86%85%E6%A0%B8%E6%9C%88%E6%8A%A5_2015.02" title="我们鼓励您登录，但这并不是必须的 [o]" accesskey="o">登录</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-logo">
		<a style="background-image: url(/skins/common/images/wiki.png);" href="/index.php?title=%E9%A6%96%E9%A1%B5" title="访问首页"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
	<div class='generated-sidebar portlet' id='p-navigation'>
		<h5>导航</h5>
		<div class='pBody'>
			<ul>
				<li id="n-mainpage-description"><a href="/index.php?title=%E9%A6%96%E9%A1%B5" title="访问首页 [z]" accesskey="z">首页</a></li>
				<li id="n-portal"><a href="/index.php?title=%E6%B7%98%E5%AE%9D%E6%95%B0%E6%8D%AE%E5%BA%93%E7%A0%94%E5%8F%91%E7%BB%84:%E7%A4%BE%E5%8C%BA" title="关于本计划，您可以做什么，应该如何做">社区入口</a></li>
				<li id="n-currentevents"><a href="/index.php?title=%E6%B7%98%E5%AE%9D%E6%95%B0%E6%8D%AE%E5%BA%93%E7%A0%94%E5%8F%91%E7%BB%84:%E5%BD%93%E5%89%8D%E4%BA%8B%E4%BB%B6" title="查找当前事件的背景信息">当前事件</a></li>
				<li id="n-recentchanges"><a href="/index.php?title=%E7%89%B9%E6%AE%8A:%E6%9C%80%E8%BF%91%E6%9B%B4%E6%94%B9" title="列出该网站的最近修改 [r]" accesskey="r">最近更改</a></li>
				<li id="n-randompage"><a href="/index.php?title=%E7%89%B9%E6%AE%8A:%E9%9A%8F%E6%9C%BA%E9%A1%B5%E9%9D%A2" title="随机载入一个页面 [x]" accesskey="x">随机页面</a></li>
				<li id="n-help"><a href="/index.php?title=%E5%B8%AE%E5%8A%A9:%E7%9B%AE%E5%BD%95" title="寻求帮助">帮助</a></li>
			</ul>
		</div>
	</div>
	<div id="p-search" class="portlet">
		<h5><label for="searchInput">搜索</label></h5>
		<div id="searchBody" class="pBody">
			<form action="/index.php" id="searchform">
				<input type='hidden' name="title" value="特殊:搜索"/>
				<input id="searchInput" title="搜索该网站" accesskey="f" type="search" name="search" />
				<input type='submit' name="go" class="searchButton" id="searchGoButton"	value="进入" title="如果相同的标题存在的话便直接前往该页面" />&nbsp;
				<input type='submit' name="fulltext" class="searchButton" id="mw-searchButton" value="搜索" title="搜索该文字的页面" />
			</form>
		</div>
	</div>
	<div class="portlet" id="p-tb">
		<h5>工具箱</h5>
		<div class="pBody">
			<ul>
				<li id="t-whatlinkshere"><a href="/index.php?title=%E7%89%B9%E6%AE%8A:%E9%93%BE%E5%85%A5%E9%A1%B5%E9%9D%A2/MySQL%E5%86%85%E6%A0%B8%E6%9C%88%E6%8A%A5_2015.02" title="列出所有与此页相链的页面 [j]" accesskey="j">链入页面</a></li>
				<li id="t-recentchangeslinked"><a href="/index.php?title=%E7%89%B9%E6%AE%8A:%E9%93%BE%E5%87%BA%E6%9B%B4%E6%94%B9/MySQL%E5%86%85%E6%A0%B8%E6%9C%88%E6%8A%A5_2015.02" title="从此页链出的所有页面的更改 [k]" accesskey="k">链出更改</a></li>
<li id="t-specialpages"><a href="/index.php?title=%E7%89%B9%E6%AE%8A:%E7%89%B9%E6%AE%8A%E9%A1%B5%E9%9D%A2" title="所有特殊页面列表 [q]" accesskey="q">特殊页面</a></li>
				<li id="t-print"><a href="/index.php?title=MySQL%E5%86%85%E6%A0%B8%E6%9C%88%E6%8A%A5_2015.02&amp;printable=yes" rel="alternate" title="这个页面的可打印版本 [p]" accesskey="p">可打印版</a></li>				<li id="t-permalink"><a href="/index.php?title=MySQL%E5%86%85%E6%A0%B8%E6%9C%88%E6%8A%A5_2015.02&amp;oldid=1226" title="这个页面修订版本的永久链接">永久链接</a></li>			</ul>
		</div>
	</div>
</div><!-- end of the left (by default at least) column -->
<div class="visualClear"></div>
<div id="footer">
	<div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="/skins/common/images/poweredby_mediawiki_88x31.png" height="31" width="88" alt="Powered by MediaWiki" /></a></div>
	<div id="f-copyrightico"><a href="http://www.gnu.org/copyleft/fdl.html"><img src="/skins/common/images/gnu-fdl.png" alt="GNU Free Documentation License 1.3" width="88" height="31" /></a></div>
	<ul id="f-list">
		<li id="lastmod"> 此页面最后修订于2015年2月16日 (星期一) 03:31。</li>
		<li id="viewcount">此页面已被浏览过7,596次。</li>
		<li id="copyright">本站全部文字内容使用<a href="http://www.gnu.org/copyleft/fdl.html" class="external ">GNU Free Documentation License 1.3</a>授权。</li>
		<li id="privacy"><a href="/index.php?title=%E6%B7%98%E5%AE%9D%E6%95%B0%E6%8D%AE%E5%BA%93%E7%A0%94%E5%8F%91%E7%BB%84:%E9%9A%90%E7%A7%81%E6%94%BF%E7%AD%96" title="淘宝数据库研发组:隐私政策">隐私政策</a></li>
		<li id="about"><a href="/index.php?title=%E6%B7%98%E5%AE%9D%E6%95%B0%E6%8D%AE%E5%BA%93%E7%A0%94%E5%8F%91%E7%BB%84:%E5%85%B3%E4%BA%8E" title="淘宝数据库研发组:关于">关于淘宝数据库研发组</a></li>
		<li id="disclaimer"><a href="/index.php?title=%E6%B7%98%E5%AE%9D%E6%95%B0%E6%8D%AE%E5%BA%93%E7%A0%94%E5%8F%91%E7%BB%84:%E5%85%8D%E8%B4%A3%E5%A3%B0%E6%98%8E" title="淘宝数据库研发组:免责声明">免责声明</a></li>
	</ul>
</div>
</div>

<script>if (window.runOnloadHook) runOnloadHook();</script>
<!-- Served in 0.049 secs. --></body></html>
